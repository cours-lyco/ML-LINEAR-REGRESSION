{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "#from keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "#import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "from tensorflow import keras\n",
    "#import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, InputLayer, UpSampling2D,Conv2D, MaxPooling2D\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''path of external device '''\n",
    "rootDir = \"/Volumes/Disk E/\"\n",
    "datasDir = rootDir + \"/crohme2016_inkml_datasets/CROHME2016_data/\"\n",
    "\n",
    "imagesDir = rootDir + \"/crohme2016_inkml_images/\"\n",
    "'''now get train valid test dir'''\n",
    "\n",
    "trainDir = datasDir + 'Task-2-Symbols/task2-trainSymb2014/'\n",
    "trainDirDatasets = trainDir + 'trainingSymbols/'\n",
    "trainDir_ground_truth = trainDir + 'trainingSymbols/iso_GT.txt'\n",
    "trainDatasImmagesDir = \"/Volumes/Disk E/crohme2016_inkml_images/train_images\"\n",
    "\n",
    "testDir = datasDir + 'Task-2-Symbols/task2-testSymbols2014/'\n",
    "testDir_ground_truth = testDir + \"testSymbols_2016_iso_GT.txt\"\n",
    "testDirDatasets = testDir + \"testSymbols/\"\n",
    "testDatasImmagesDir = \"/Volumes/Disk E/crohme2016_inkml_images/test_images\"\n",
    "\n",
    "valDir = datasDir + 'Task-2-Symbols/task2-validation-isolatedTest2013b/'\n",
    "valDirDatasets = datasDir + 'Task-2-Symbols/task2-validation-isolatedTest2013b/'\n",
    "valDir_ground_truth = valDirDatasets + 'iso_GT.txt'\n",
    "valDatasImmagesDir = \"/Volumes/Disk E/crohme2016_inkml_images/val_images\"\n",
    "\n",
    "models_save = \"/Volumes/Disk E/models_save/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(object):\n",
    "\n",
    "    differents_characters = 101\n",
    "    image_len = 28\n",
    "    X_train_len = 85802\n",
    "    X_test_len = 18435\n",
    "    X_val_len = 12504\n",
    "\n",
    "    def __init__(self):\n",
    "        self.X_train, self.X_test, self.X_val = [], [], []\n",
    "        self.y_train, self.y_test, self.y_val = [], [], []\n",
    "\n",
    "        self.y_train_character_ordered = []\n",
    "        self.y_test_character_ordered = []\n",
    "        self.y_val_character_ordered = []\n",
    "\n",
    "        #self.gt = [ {sortedDictTrain}  , {sortedDictTest}, {sortedDictval} ]\n",
    "        #sortedDictTrain = ')' : [chemin de ttes les images de parenthÃ¨ses], '9': [chemin de ttes les images de 9],  ...\n",
    "        self.gt = {}\n",
    "\n",
    "        '''first load grounth truth and prevent junk data to load '''\n",
    "        self.get_all_images_categorical()\n",
    "        '''second load images and prevent junk images  to load '''\n",
    "        self.get_all_images_Matrix()\n",
    "\n",
    "        self.X_train, self.X_test, self.X_val = np.array(\n",
    "            self.X_train), np.array(self.X_test), np.array(self.X_val)\n",
    "        self.y_train, self.y_test, self.y_val = np.array(\n",
    "            self.y_train), np.array(self.y_test), np.array(self.y_val)\n",
    "        \n",
    "        self.X_train, self.X_test,  self.X_val = (self.X_train - np.mean(self.X_train)) / np.std(self.X_train), (self.X_test - np.mean(self.X_test)) / np.std(\n",
    "            self.X_test), (self.X_val - np.mean(self.X_val)) / np.std(self.X_val)\n",
    "        \n",
    "    def get_matrix_from_image(self, infilename):\n",
    "        img = Image.open(infilename)\n",
    "        img.load()\n",
    "        imageMatrix = np.asarray(img, dtype=\"float32\")/255.0\n",
    "        return imageMatrix\n",
    "    #------------------------------------------------------------------------------------------------------#\n",
    "    #                         GET TRAIN RESAUL\n",
    "    #-------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    def get_which_character(y):\n",
    "        pass\n",
    "    #------------------------------------------------------------------------------------------------------#\n",
    "    # result: X_train = [imageMatrix_iso0.png, imageMatrix_iso0.png, ........., imageMatrix_iso85802.png ]\n",
    "    #         X_test = [imageMatrix_iso0.png, imageMatrix_iso0.png, ........., imageMatrix_iso18402.png  ]\n",
    "    #         X_val = [imageMatrix_iso0.png, imageMatrix_iso0.png, ........., imageMatrix_iso18402.png ]\n",
    "    #--------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    def get_all_images_Matrix(self):\n",
    "        directories = [trainDatasImmagesDir,\n",
    "                       testDatasImmagesDir, valDatasImmagesDir]\n",
    "        if not self.gt:\n",
    "            print(\"Error no ground truth to prevent to load junk image\")\n",
    "            return\n",
    "        for index, data_dir_abs_path in enumerate(directories):\n",
    "            print(\"loding image ..............\\n\")\n",
    "            if os.path.isdir(data_dir_abs_path):\n",
    "                if index == 0:\n",
    "                    slice_start, slice_stop = 3, -4\n",
    "                    ground_truth = self.gt['train_gt']\n",
    "                if index == 1:\n",
    "                    slice_start, slice_stop = 3, -4\n",
    "                    ground_truth = self.gt['test_gt']\n",
    "                if index == 2:\n",
    "                    slice_start, slice_stop = 4, -4\n",
    "                    ground_truth = self.gt['val_gt']\n",
    "\n",
    "                print(\".... start loading  in folder: {}\".format(data_dir_abs_path))\n",
    "                #get array of files\n",
    "                images_files_array = sorted(\n",
    "                    glob.glob(data_dir_abs_path + os.sep + \"*.png\"))\n",
    "\n",
    "                #sort files array\n",
    "                images_files_array = sorted(images_files_array, key=lambda name: int(\n",
    "                    (os.path.basename(name))[slice_start: slice_stop]))\n",
    "\n",
    "                #inkml_files = inkml_files.sort(key=self.sortGlobFilesArray)\n",
    "                for j, image_file_abs_path in enumerate(images_files_array):\n",
    "\n",
    "                    file_name_index = image_file_abs_path.split('/')[-1]\n",
    "                    file_name_index = file_name_index[int(\n",
    "                        slice_start): int(slice_stop)]\n",
    "                    #print(\".............fle check: {} .............\".format(file_name_index))\n",
    "                    file_is_junk = True\n",
    "                    for key in ground_truth:\n",
    "                        if file_name_index in ground_truth[key]:\n",
    "                            file_is_junk = False\n",
    "                    if False == file_is_junk:\n",
    "                        imageMatrix = self.get_matrix_from_image(\n",
    "                            image_file_abs_path).reshape(28, 28, 1)\n",
    "\n",
    "                        if index == 0:\n",
    "                            self.X_train.append(imageMatrix)\n",
    "                        if index == 1:\n",
    "                            self.X_test.append(imageMatrix)\n",
    "                        if index == 2:\n",
    "                            self.X_val.append(imageMatrix)\n",
    "                    #else:\n",
    "                        #print('...............Found JUNK FILE .....................\\n')\n",
    "                '--------------------------------------------------------------------'\n",
    "\n",
    "                '--------------------------------------------------------------------'\n",
    "                if index == 0:\n",
    "                    print(\"------- LEN IMAGES FILES: \", len(self.X_train))\n",
    "                if index == 1:\n",
    "                    print(\"------- LEN IMAGES FILES: \", len(self.X_test))\n",
    "                if index == 2:\n",
    "                    print(\"------- LEN IMAGES FILES: \", len(self.X_val))\n",
    "\n",
    "            else:\n",
    "                print(\"Error: External Devices not found\\n\")\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------------#\n",
    "    #  Result: y_train = Matrix 101 x 101, y_test = Matrix 101 x 101, y_val = Matrix 101 x 101\n",
    "    #---------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    def get_all_images_categorical(self):\n",
    "        gt_directories_files = [trainDir_ground_truth,\n",
    "                                testDir_ground_truth, valDir_ground_truth]\n",
    "        imagesDir = [trainDatasImmagesDir,\n",
    "                     testDatasImmagesDir, valDatasImmagesDir]\n",
    "\n",
    "        for index, abs_gt_file_path in enumerate(gt_directories_files):\n",
    "            #print(\"Start reading grount truth ..... {}\" .format(os.path.basename(abs_gt_file_path)))\n",
    "            sorted_gt, total_character, y = self.read_gt(\n",
    "                abs_gt_file_path, imagesDir[index])\n",
    "\n",
    "            length = len(sorted_gt.keys())\n",
    "\n",
    "            for i, el in enumerate(y):\n",
    "                x = np.zeros(length, dtype=np.float32)\n",
    "                x[el] = 1.0\n",
    "\n",
    "                if index == 0:\n",
    "                    self.y_train.append(x)\n",
    "                    self.gt['train_gt'] = sorted_gt\n",
    "                if index == 1:\n",
    "                    self.y_test.append(x)\n",
    "                    self.gt['test_gt'] = sorted_gt\n",
    "                if index == 2:\n",
    "                    self.y_val.append(x)\n",
    "                    self.gt['val_gt'] = sorted_gt\n",
    "\n",
    "    #------------------------------------------------------------------------------#\n",
    "    # return a Dictionary\n",
    "    # {\n",
    "    # ')' : [abs_path_image1, abs_path_imag2, ...]\n",
    "    #    .....................................\n",
    "    #   '!'  : [abs_path_image14, abs_path_imag267, ...]\n",
    "    # }\n",
    "    #------------------------------------------------------------------------------#\n",
    "\n",
    "    def read_gt(self, abs_gt_file_path, imagesDir):\n",
    "        '''Loads the routes of the png files'''\n",
    "        try:\n",
    "            fileName = os.path.basename(abs_gt_file_path)\n",
    "            print(\"reading ground truth {} ..................\".format(fileName))\n",
    "            with open(abs_gt_file_path) as file:\n",
    "                lines = file.readlines()\n",
    "\n",
    "                aDict = {}\n",
    "                aLabelsSet = []\n",
    "                total_character = 0\n",
    "                all_labels = []\n",
    "\n",
    "                for index, line in enumerate(lines):\n",
    "                    line = line.strip()\n",
    "\n",
    "                    parts = line.split(',')\n",
    "                    label = parts[1].strip()\n",
    "\n",
    "                    data = parts[0].split('_')\n",
    "                    index = data[-1].strip()\n",
    "                    if(label != 'junk'):\n",
    "                        all_labels.append(label)\n",
    "                    if label not in aLabelsSet and label != 'junk':\n",
    "                        aLabelsSet.append(label)\n",
    "\n",
    "                    if label in aDict and label != 'junk':\n",
    "                        #aDict[label].append(imagesDir + '/' + 'iso' + index + '.png')\n",
    "                        aDict[label].append(index)\n",
    "                    else:\n",
    "                        #aDict[label] = [imagesDir + '/' + 'iso' + index + '.png']\n",
    "                        aDict[label] = [index]\n",
    "                    total_character = total_character + 1\n",
    "\n",
    "            #sort dictionary but others method doesn't work\n",
    "            bDict = {}\n",
    "            y = []\n",
    "            for label in aLabelsSet:\n",
    "                bDict[label] = aDict[label]\n",
    "            for label in all_labels:\n",
    "                for i, el in enumerate(aLabelsSet):\n",
    "                    if(el == label):\n",
    "                        y.append(i)\n",
    "\n",
    "            #aDict = OrderedDict(sorted(aDict.items(), key=lambda t: t[0]))\n",
    "            # print(\"dictionnary sorted keys : \", bDict.keys())\n",
    "            print(\"Finish readin ground {} truth: {}\".format(fileName, len(bDict)))\n",
    "            #print(\"bDict length:........\", len(bDict))\n",
    "\n",
    "            return bDict, total_character, y\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(e)\n",
    "\n",
    "    def create_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(InputLayer(input_shape=self.X_train.shape[1:]))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2,\n",
    "                 kernel_initializer='truncated_normal'))\n",
    "        model.add(MaxPooling2D((3, 3), strides=1, padding='same'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "                 kernel_initializer='truncated_normal'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2,\n",
    "                 kernel_initializer='truncated_normal'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=1,\n",
    "                 kernel_initializer='truncated_normal'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2,\n",
    "                 kernel_initializer='truncated_normal'))\n",
    "        model.add(MaxPooling2D((3, 3), strides=1, padding='same'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=1,\n",
    "                 kernel_initializer='truncated_normal'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=1,\n",
    "                 kernel_initializer='truncated_normal'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=1,\n",
    "                 kernel_initializer='truncated_normal'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=1,\n",
    "                 kernel_initializer='truncated_normal'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(101, activation='softmax'))\n",
    "        #model.add(UpSampling2D((2, 2)))\n",
    "        return model\n",
    "\n",
    "    def compile_model(self, model):\n",
    "        #compile model using accuracy to measure model performance\n",
    "        # Compile the model\n",
    "        #model.compile(\n",
    "            #loss=keras.losses.mean_squared_error, optimizer='sgd')\n",
    "        optimizer = tf.keras.optimizers.RMSprop( lr = 0.0005, decay = 1e-5 )\n",
    "        model.compile( optimizer=optimizer, loss='mse', metrics=['acc'] )\n",
    "        return model\n",
    "\n",
    "    def train_model(self, model):\n",
    "        #fit the model\n",
    "        #model.fit(self.X_train, self.y_train, batch_size=500, epochs=10)\n",
    "        # Evaluate the model on test set\n",
    "        #score = model.evaluate(self.X_test, self.y_test, verbose=0)\n",
    "        # Print test accuracy\n",
    "        #print('\\nTest accuracy: {}'.format(score[1]*100))\n",
    "        model.fit(self.X_train, self.y_train, batch_size=400, validation_data=(self.X_test, self.y_test), epochs=100)\n",
    "        return model\n",
    "\n",
    "    def save_model(self, model):\n",
    "        # save model and architecture to single file\n",
    "        model.save(models_save + \"model.h5\")\n",
    "        print(\"Saved model to disk\")\n",
    "        return model\n",
    "\n",
    "    def load_saved_model(self, model):\n",
    "        model = load_model(models_save + \"model.h5\")\n",
    "        # summarize model.\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "    def evaluate_model(self, model):\n",
    "        score = model.evaluate(self.X_val, self.y_val, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "    def model_predict(self, model, X):\n",
    "        #predict first 4 images in the test set\n",
    "        re\n",
    "        #np.argmax(result_digit_1 ,axis = 1)\n",
    "        return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading ground truth iso_GT.txt ..................\n",
      "Finish readin ground iso_GT.txt truth: 101\n",
      "reading ground truth testSymbols_2016_iso_GT.txt ..................\n",
      "Finish readin ground testSymbols_2016_iso_GT.txt truth: 101\n",
      "reading ground truth iso_GT.txt ..................\n",
      "Finish readin ground iso_GT.txt truth: 101\n",
      "loding image ..............\n",
      "\n",
      ".... start loading  in folder: /Volumes/Disk E/crohme2016_inkml_images/train_images\n",
      "------- LEN IMAGES FILES:  85802\n",
      "loding image ..............\n",
      "\n",
      ".... start loading  in folder: /Volumes/Disk E/crohme2016_inkml_images/test_images\n",
      "------- LEN IMAGES FILES:  10019\n",
      "loding image ..............\n",
      "\n",
      ".... start loading  in folder: /Volumes/Disk E/crohme2016_inkml_images/val_images\n",
      "------- LEN IMAGES FILES:  6083\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85802, 101)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn.compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 85802 samples, validate on 10019 samples\n",
      "Epoch 1/1800\n",
      "85802/85802 [==============================] - 975s 11ms/sample - loss: 0.0040 - acc: 0.7175 - val_loss: 0.0180 - val_acc: 0.0015\n",
      "Epoch 2/1800\n",
      "81621/85802 [===========================>..] - ETA: 40s - loss: 0.0025 - acc: 0.8360"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-7012e274979b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-47-8f71957a79f3>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# Print test accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;31m#print('\\nTest accuracy: {}'.format(score[1]*100))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/machine_learning_env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/miniconda3/envs/machine_learning_env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/machine_learning_env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/machine_learning_env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/machine_learning_env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/machine_learning_env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/machine_learning_env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/machine_learning_env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/machine_learning_env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/machine_learning_env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/miniconda3/envs/machine_learning_env/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = cnn.train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
