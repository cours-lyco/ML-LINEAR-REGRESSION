{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "#from keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "#import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "from tensorflow import keras\n",
    "#import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, InputLayer, UpSampling2D,Conv2D, MaxPooling2D\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''path of external device '''\n",
    "rootDir = \"/Volumes/Disk E/\"\n",
    "datasDir = rootDir + \"/crohme2016_inkml_datasets/CROHME2016_data/\"\n",
    "\n",
    "imagesDir = rootDir + \"/crohme2016_inkml_images/\"\n",
    "'''now get train valid test dir'''\n",
    "\n",
    "trainDir = datasDir + 'Task-2-Symbols/task2-trainSymb2014/'\n",
    "trainDirDatasets = trainDir + 'trainingSymbols/'\n",
    "trainDir_ground_truth = trainDir + 'trainingSymbols/iso_GT.txt'\n",
    "trainDatasImmagesDir = \"/Volumes/Disk E/crohme2016_inkml_images/train_images\"\n",
    "\n",
    "testDir = datasDir + 'Task-2-Symbols/task2-testSymbols2014/'\n",
    "testDir_ground_truth = testDir + \"testSymbols_2016_iso_GT.txt\"\n",
    "testDirDatasets = testDir + \"testSymbols/\"\n",
    "testDatasImmagesDir = \"/Volumes/Disk E/crohme2016_inkml_images/test_images\"\n",
    "\n",
    "valDir = datasDir + 'Task-2-Symbols/task2-validation-isolatedTest2013b/'\n",
    "valDirDatasets = datasDir + 'Task-2-Symbols/task2-validation-isolatedTest2013b/'\n",
    "valDir_ground_truth = valDirDatasets + 'iso_GT.txt'\n",
    "valDatasImmagesDir = \"/Volumes/Disk E/crohme2016_inkml_images/val_images\"\n",
    "\n",
    "models_save = \"/Volumes/Disk E/models_save/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(object):\n",
    "\n",
    "    differents_characters = 101\n",
    "    image_len = 28\n",
    "    X_train_len = 85802\n",
    "    X_test_len = 18435\n",
    "    X_val_len = 12504\n",
    "\n",
    "    def __init__(self):\n",
    "        self.X_train, self.X_test, self.X_val = [], [], []\n",
    "        self.y_train, self.y_test, self.y_val = [], [], []\n",
    "\n",
    "        self.y_train_character_ordered = []\n",
    "        self.y_test_character_ordered = []\n",
    "        self.y_val_character_ordered = []\n",
    "\n",
    "        #self.gt = [ {sortedDictTrain}  , {sortedDictTest}, {sortedDictval} ]\n",
    "        #sortedDictTrain = ')' : [chemin de ttes les images de parenth√®ses], '9': [chemin de ttes les images de 9],  ...\n",
    "        self.gt = {}\n",
    "\n",
    "        '''first load grounth truth and prevent junk data to load '''\n",
    "        self.get_all_images_categorical()\n",
    "        '''second load images and prevent junk images  to load '''\n",
    "        self.get_all_images_Matrix()\n",
    "\n",
    "        self.X_train, self.X_test, self.X_val = np.array(\n",
    "            self.X_train), np.array(self.X_test), np.array(self.X_val)\n",
    "        self.y_train, self.y_test, self.y_val = np.array(\n",
    "            self.y_train), np.array(self.y_test), np.array(self.y_val)\n",
    "        \n",
    "        self.X_train, self.X_test,  self.X_val = (self.X_train - np.mean(self.X_train)) / np.std(self.X_train), (self.X_test - np.mean(self.X_test)) / np.std(\n",
    "            self.X_test), (self.X_val - np.mean(self.X_val)) / np.std(self.X_val)\n",
    "        \n",
    "    def get_matrix_from_image(self, infilename):\n",
    "        img = Image.open(infilename)\n",
    "        img.load()\n",
    "        imageMatrix = np.asarray(img, dtype=\"float32\")/255.0\n",
    "        return imageMatrix\n",
    "    #------------------------------------------------------------------------------------------------------#\n",
    "    #                         GET TRAIN RESAUL\n",
    "    #-------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    def get_which_character(y):\n",
    "        pass\n",
    "    #------------------------------------------------------------------------------------------------------#\n",
    "    # result: X_train = [imageMatrix_iso0.png, imageMatrix_iso0.png, ........., imageMatrix_iso85802.png ]\n",
    "    #         X_test = [imageMatrix_iso0.png, imageMatrix_iso0.png, ........., imageMatrix_iso18402.png  ]\n",
    "    #         X_val = [imageMatrix_iso0.png, imageMatrix_iso0.png, ........., imageMatrix_iso18402.png ]\n",
    "    #--------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    def get_all_images_Matrix(self):\n",
    "        directories = [trainDatasImmagesDir,\n",
    "                       testDatasImmagesDir, valDatasImmagesDir]\n",
    "        if not self.gt:\n",
    "            print(\"Error no ground truth to prevent to load junk image\")\n",
    "            return\n",
    "        for index, data_dir_abs_path in enumerate(directories):\n",
    "            print(\"loding image ..............\\n\")\n",
    "            if os.path.isdir(data_dir_abs_path):\n",
    "                if index == 0:\n",
    "                    slice_start, slice_stop = 3, -4\n",
    "                    ground_truth = self.gt['train_gt']\n",
    "                if index == 1:\n",
    "                    slice_start, slice_stop = 3, -4\n",
    "                    ground_truth = self.gt['test_gt']\n",
    "                if index == 2:\n",
    "                    slice_start, slice_stop = 4, -4\n",
    "                    ground_truth = self.gt['val_gt']\n",
    "\n",
    "                print(\".... start loading  in folder: {}\".format(data_dir_abs_path))\n",
    "                #get array of files\n",
    "                images_files_array = sorted(\n",
    "                    glob.glob(data_dir_abs_path + os.sep + \"*.png\"))\n",
    "\n",
    "                #sort files array\n",
    "                images_files_array = sorted(images_files_array, key=lambda name: int(\n",
    "                    (os.path.basename(name))[slice_start: slice_stop]))\n",
    "\n",
    "                #inkml_files = inkml_files.sort(key=self.sortGlobFilesArray)\n",
    "                for j, image_file_abs_path in enumerate(images_files_array):\n",
    "\n",
    "                    file_name_index = image_file_abs_path.split('/')[-1]\n",
    "                    file_name_index = file_name_index[int(\n",
    "                        slice_start): int(slice_stop)]\n",
    "                    #print(\".............fle check: {} .............\".format(file_name_index))\n",
    "                    file_is_junk = True\n",
    "                    for key in ground_truth:\n",
    "                        if file_name_index in ground_truth[key]:\n",
    "                            file_is_junk = False\n",
    "                    if False == file_is_junk:\n",
    "                        imageMatrix = self.get_matrix_from_image(\n",
    "                            image_file_abs_path).reshape(28, 28, 1)\n",
    "\n",
    "                        if index == 0:\n",
    "                            self.X_train.append(imageMatrix)\n",
    "                        if index == 1:\n",
    "                            self.X_test.append(imageMatrix)\n",
    "                        if index == 2:\n",
    "                            self.X_val.append(imageMatrix)\n",
    "                    #else:\n",
    "                        #print('...............Found JUNK FILE .....................\\n')\n",
    "                '--------------------------------------------------------------------'\n",
    "\n",
    "                '--------------------------------------------------------------------'\n",
    "                if index == 0:\n",
    "                    print(\"------- LEN IMAGES FILES: \", len(self.X_train))\n",
    "                if index == 1:\n",
    "                    print(\"------- LEN IMAGES FILES: \", len(self.X_test))\n",
    "                if index == 2:\n",
    "                    print(\"------- LEN IMAGES FILES: \", len(self.X_val))\n",
    "\n",
    "            else:\n",
    "                print(\"Error: External Devices not found\\n\")\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------------#\n",
    "    #  Result: y_train = Matrix 101 x 101, y_test = Matrix 101 x 101, y_val = Matrix 101 x 101\n",
    "    #---------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    def get_all_images_categorical(self):\n",
    "        gt_directories_files = [trainDir_ground_truth,\n",
    "                                testDir_ground_truth, valDir_ground_truth]\n",
    "        imagesDir = [trainDatasImmagesDir,\n",
    "                     testDatasImmagesDir, valDatasImmagesDir]\n",
    "\n",
    "        for index, abs_gt_file_path in enumerate(gt_directories_files):\n",
    "            #print(\"Start reading grount truth ..... {}\" .format(os.path.basename(abs_gt_file_path)))\n",
    "            sorted_gt, total_character, y = self.read_gt(\n",
    "                abs_gt_file_path, imagesDir[index])\n",
    "\n",
    "            length = len(sorted_gt.keys())\n",
    "\n",
    "            for i, el in enumerate(y):\n",
    "                x = np.zeros(length, dtype=np.float32)\n",
    "                x[el] = 1.0\n",
    "\n",
    "                if index == 0:\n",
    "                    self.y_train.append(x)\n",
    "                    self.gt['train_gt'] = sorted_gt\n",
    "                if index == 1:\n",
    "                    self.y_test.append(x)\n",
    "                    self.gt['test_gt'] = sorted_gt\n",
    "                if index == 2:\n",
    "                    self.y_val.append(x)\n",
    "                    self.gt['val_gt'] = sorted_gt\n",
    "\n",
    "    #------------------------------------------------------------------------------#\n",
    "    # return a Dictionary\n",
    "    # {\n",
    "    # ')' : [abs_path_image1, abs_path_imag2, ...]\n",
    "    #    .....................................\n",
    "    #   '!'  : [abs_path_image14, abs_path_imag267, ...]\n",
    "    # }\n",
    "    #------------------------------------------------------------------------------#\n",
    "\n",
    "    def read_gt(self, abs_gt_file_path, imagesDir):\n",
    "        '''Loads the routes of the png files'''\n",
    "        try:\n",
    "            fileName = os.path.basename(abs_gt_file_path)\n",
    "            print(\"reading ground truth {} ..................\".format(fileName))\n",
    "            with open(abs_gt_file_path) as file:\n",
    "                lines = file.readlines()\n",
    "\n",
    "                aDict = {}\n",
    "                aLabelsSet = []\n",
    "                total_character = 0\n",
    "                all_labels = []\n",
    "\n",
    "                for index, line in enumerate(lines):\n",
    "                    line = line.strip()\n",
    "\n",
    "                    parts = line.split(',')\n",
    "                    label = parts[1].strip()\n",
    "\n",
    "                    data = parts[0].split('_')\n",
    "                    index = data[-1].strip()\n",
    "                    if(label != 'junk'):\n",
    "                        all_labels.append(label)\n",
    "                    if label not in aLabelsSet and label != 'junk':\n",
    "                        aLabelsSet.append(label)\n",
    "\n",
    "                    if label in aDict and label != 'junk':\n",
    "                        #aDict[label].append(imagesDir + '/' + 'iso' + index + '.png')\n",
    "                        aDict[label].append(index)\n",
    "                    else:\n",
    "                        #aDict[label] = [imagesDir + '/' + 'iso' + index + '.png']\n",
    "                        aDict[label] = [index]\n",
    "                    total_character = total_character + 1\n",
    "\n",
    "            #sort dictionary but others method doesn't work\n",
    "            bDict = {}\n",
    "            y = []\n",
    "            for label in aLabelsSet:\n",
    "                bDict[label] = aDict[label]\n",
    "            for label in all_labels:\n",
    "                for i, el in enumerate(aLabelsSet):\n",
    "                    if(el == label):\n",
    "                        y.append(i)\n",
    "\n",
    "            #aDict = OrderedDict(sorted(aDict.items(), key=lambda t: t[0]))\n",
    "            # print(\"dictionnary sorted keys : \", bDict.keys())\n",
    "            print(\"Finish readin ground {} truth: {}\".format(fileName, len(bDict)))\n",
    "            #print(\"bDict length:........\", len(bDict))\n",
    "\n",
    "            return bDict, total_character, y\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(e)\n",
    "\n",
    "    def create_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(InputLayer(input_shape=self.X_train.shape[1:]))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2,\n",
    "                 kernel_initializer='truncated_normal'))\n",
    "        model.add(MaxPooling2D((3, 3), strides=1, padding='same'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "                 kernel_initializer='truncated_normal'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2,\n",
    "                 kernel_initializer='truncated_normal'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=1,\n",
    "                 kernel_initializer='truncated_normal'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2,\n",
    "                 kernel_initializer='truncated_normal'))\n",
    "        model.add(MaxPooling2D((3, 3), strides=1, padding='same'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=1,\n",
    "                 kernel_initializer='truncated_normal'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=1,\n",
    "                 kernel_initializer='truncated_normal'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=1,\n",
    "                 kernel_initializer='truncated_normal'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=1,\n",
    "                 kernel_initializer='truncated_normal'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(101, activation='softmax'))\n",
    "        #model.add(UpSampling2D((2, 2)))\n",
    "        return model\n",
    "\n",
    "    def compile_model(self, model):\n",
    "        #compile model using accuracy to measure model performance\n",
    "        # Compile the model\n",
    "        #model.compile(\n",
    "            #loss=keras.losses.mean_squared_error, optimizer='sgd')\n",
    "        optimizer = tf.keras.optimizers.RMSprop( lr = 0.0005, decay = 1e-5 )\n",
    "        model.compile( optimizer=optimizer, loss='mse', metrics=['acc'] )\n",
    "        return model\n",
    "\n",
    "    def train_model(self, model):\n",
    "        #fit the model\n",
    "        #model.fit(self.X_train, self.y_train, batch_size=500, epochs=10)\n",
    "        # Evaluate the model on test set\n",
    "        #score = model.evaluate(self.X_test, self.y_test, verbose=0)\n",
    "        # Print test accuracy\n",
    "        #print('\\nTest accuracy: {}'.format(score[1]*100))\n",
    "        model.fit(self.X_train, self.y_train, batch_size=400, validation_data=(self.X_test, self.y_test), epochs=100)\n",
    "        return model\n",
    "\n",
    "    def save_model(self, model):\n",
    "        # save model and architecture to single file\n",
    "        model.save(models_save + \"model.h5\")\n",
    "        print(\"Saved model to disk\")\n",
    "        return model\n",
    "\n",
    "    def load_saved_model(self, model):\n",
    "        model = load_model(models_save + \"model.h5\")\n",
    "        # summarize model.\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "    def evaluate_model(self, model):\n",
    "        score = model.evaluate(self.X_val, self.y_val, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "    def model_predict(self, model, X):\n",
    "        #predict first 4 images in the test set\n",
    "        re\n",
    "        #np.argmax(result_digit_1 ,axis = 1)\n",
    "        return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading ground truth iso_GT.txt ..................\n",
      "Finish readin ground iso_GT.txt truth: 101\n",
      "reading ground truth testSymbols_2016_iso_GT.txt ..................\n",
      "Finish readin ground testSymbols_2016_iso_GT.txt truth: 101\n",
      "reading ground truth iso_GT.txt ..................\n",
      "Finish readin ground iso_GT.txt truth: 101\n",
      "loding image ..............\n",
      "\n",
      ".... start loading  in folder: /Volumes/Disk E/crohme2016_inkml_images/train_images\n",
      "------- LEN IMAGES FILES:  85802\n",
      "loding image ..............\n",
      "\n",
      ".... start loading  in folder: /Volumes/Disk E/crohme2016_inkml_images/test_images\n",
      "------- LEN IMAGES FILES:  10019\n",
      "loding image ..............\n",
      "\n",
      ".... start loading  in folder: /Volumes/Disk E/crohme2016_inkml_images/val_images\n",
      "------- LEN IMAGES FILES:  6083\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85802, 101)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn.compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 85802 samples, validate on 10019 samples\n",
      "Epoch 1/100\n",
      "85802/85802 [==============================] - 157s 2ms/sample - loss: 0.0074 - acc: 0.3777 - val_loss: 0.0147 - val_acc: 0.0027\n",
      "Epoch 2/100\n",
      "85802/85802 [==============================] - 135s 2ms/sample - loss: 0.0039 - acc: 0.7147 - val_loss: 0.0166 - val_acc: 0.0028\n",
      "Epoch 3/100\n",
      "85802/85802 [==============================] - 135s 2ms/sample - loss: 0.0028 - acc: 0.8013 - val_loss: 0.0168 - val_acc: 0.0022\n",
      "Epoch 4/100\n",
      "85802/85802 [==============================] - 143s 2ms/sample - loss: 0.0024 - acc: 0.8355 - val_loss: 0.0178 - val_acc: 0.0023\n",
      "Epoch 5/100\n",
      "85802/85802 [==============================] - 134s 2ms/sample - loss: 0.0021 - acc: 0.8567 - val_loss: 0.0175 - val_acc: 0.0051\n",
      "Epoch 6/100\n",
      "85802/85802 [==============================] - 134s 2ms/sample - loss: 0.0019 - acc: 0.8714 - val_loss: 0.0180 - val_acc: 0.0026\n",
      "Epoch 7/100\n",
      "85802/85802 [==============================] - 154s 2ms/sample - loss: 0.0017 - acc: 0.8822 - val_loss: 0.0174 - val_acc: 0.0012\n",
      "Epoch 8/100\n",
      "85802/85802 [==============================] - 137s 2ms/sample - loss: 0.0016 - acc: 0.8894 - val_loss: 0.0178 - val_acc: 8.9829e-04\n",
      "Epoch 9/100\n",
      "85802/85802 [==============================] - 135s 2ms/sample - loss: 0.0015 - acc: 0.8961 - val_loss: 0.0181 - val_acc: 0.0014\n",
      "Epoch 10/100\n",
      "85802/85802 [==============================] - 134s 2ms/sample - loss: 0.0014 - acc: 0.9016 - val_loss: 0.0178 - val_acc: 0.0026\n",
      "Epoch 11/100\n",
      "85802/85802 [==============================] - 136s 2ms/sample - loss: 0.0014 - acc: 0.9062 - val_loss: 0.0181 - val_acc: 7.9848e-04\n",
      "Epoch 12/100\n",
      "85802/85802 [==============================] - 158s 2ms/sample - loss: 0.0013 - acc: 0.9128 - val_loss: 0.0176 - val_acc: 0.0019\n",
      "Epoch 13/100\n",
      "85802/85802 [==============================] - 158s 2ms/sample - loss: 0.0012 - acc: 0.9170 - val_loss: 0.0181 - val_acc: 0.0014\n",
      "Epoch 14/100\n",
      "85802/85802 [==============================] - 154s 2ms/sample - loss: 0.0012 - acc: 0.9213 - val_loss: 0.0187 - val_acc: 0.0011\n",
      "Epoch 15/100\n",
      "85802/85802 [==============================] - 158s 2ms/sample - loss: 0.0011 - acc: 0.9240 - val_loss: 0.0182 - val_acc: 8.9829e-04\n",
      "Epoch 16/100\n",
      "85802/85802 [==============================] - 156s 2ms/sample - loss: 0.0011 - acc: 0.9270 - val_loss: 0.0181 - val_acc: 6.9867e-04\n",
      "Epoch 17/100\n",
      "85802/85802 [==============================] - 143s 2ms/sample - loss: 0.0010 - acc: 0.9303 - val_loss: 0.0185 - val_acc: 7.9848e-04\n",
      "Epoch 18/100\n",
      "85802/85802 [==============================] - 146s 2ms/sample - loss: 0.0010 - acc: 0.9330 - val_loss: 0.0185 - val_acc: 0.0020\n",
      "Epoch 19/100\n",
      "85802/85802 [==============================] - 162s 2ms/sample - loss: 9.6854e-04 - acc: 0.9353 - val_loss: 0.0185 - val_acc: 0.0028\n",
      "Epoch 20/100\n",
      "85802/85802 [==============================] - 154s 2ms/sample - loss: 9.4215e-04 - acc: 0.9377 - val_loss: 0.0186 - val_acc: 9.9810e-04\n",
      "Epoch 21/100\n",
      "85802/85802 [==============================] - 153s 2ms/sample - loss: 9.1744e-04 - acc: 0.9393 - val_loss: 0.0187 - val_acc: 0.0017\n",
      "Epoch 22/100\n",
      "85802/85802 [==============================] - 145s 2ms/sample - loss: 8.9192e-04 - acc: 0.9412 - val_loss: 0.0186 - val_acc: 0.0012\n",
      "Epoch 23/100\n",
      "85802/85802 [==============================] - 150s 2ms/sample - loss: 8.6737e-04 - acc: 0.9426 - val_loss: 0.0184 - val_acc: 0.0018\n",
      "Epoch 24/100\n",
      "85802/85802 [==============================] - 139s 2ms/sample - loss: 8.4150e-04 - acc: 0.9446 - val_loss: 0.0186 - val_acc: 0.0026\n",
      "Epoch 25/100\n",
      "85802/85802 [==============================] - 145s 2ms/sample - loss: 8.2231e-04 - acc: 0.9455 - val_loss: 0.0187 - val_acc: 0.0016\n",
      "Epoch 26/100\n",
      "85802/85802 [==============================] - 136s 2ms/sample - loss: 8.0234e-04 - acc: 0.9471 - val_loss: 0.0185 - val_acc: 0.0021\n",
      "Epoch 27/100\n",
      "85802/85802 [==============================] - 154s 2ms/sample - loss: 7.8128e-04 - acc: 0.9490 - val_loss: 0.0187 - val_acc: 0.0020\n",
      "Epoch 28/100\n",
      "85802/85802 [==============================] - 149s 2ms/sample - loss: 7.6949e-04 - acc: 0.9491 - val_loss: 0.0187 - val_acc: 8.9829e-04\n",
      "Epoch 29/100\n",
      "85802/85802 [==============================] - 135s 2ms/sample - loss: 7.4974e-04 - acc: 0.9506 - val_loss: 0.0187 - val_acc: 0.0011\n",
      "Epoch 30/100\n",
      "85802/85802 [==============================] - 147s 2ms/sample - loss: 7.3870e-04 - acc: 0.9515 - val_loss: 0.0187 - val_acc: 0.0021\n",
      "Epoch 31/100\n",
      "85802/85802 [==============================] - 140s 2ms/sample - loss: 7.2205e-04 - acc: 0.9526 - val_loss: 0.0187 - val_acc: 0.0036\n",
      "Epoch 32/100\n",
      "85802/85802 [==============================] - 138s 2ms/sample - loss: 7.1154e-04 - acc: 0.9536 - val_loss: 0.0186 - val_acc: 0.0016\n",
      "Epoch 33/100\n",
      "85802/85802 [==============================] - 141s 2ms/sample - loss: 6.9669e-04 - acc: 0.9543 - val_loss: 0.0188 - val_acc: 0.0012\n",
      "Epoch 34/100\n",
      "85802/85802 [==============================] - 139s 2ms/sample - loss: 6.8100e-04 - acc: 0.9551 - val_loss: 0.0189 - val_acc: 0.0015\n",
      "Epoch 35/100\n",
      "85802/85802 [==============================] - 137s 2ms/sample - loss: 6.7329e-04 - acc: 0.9558 - val_loss: 0.0188 - val_acc: 0.0017\n",
      "Epoch 36/100\n",
      "85802/85802 [==============================] - 154s 2ms/sample - loss: 6.5678e-04 - acc: 0.9569 - val_loss: 0.0188 - val_acc: 0.0011\n",
      "Epoch 37/100\n",
      "85802/85802 [==============================] - 158s 2ms/sample - loss: 6.3904e-04 - acc: 0.9581 - val_loss: 0.0189 - val_acc: 0.0011\n",
      "Epoch 38/100\n",
      "85802/85802 [==============================] - 153s 2ms/sample - loss: 6.3606e-04 - acc: 0.9588 - val_loss: 0.0187 - val_acc: 0.0017\n",
      "Epoch 39/100\n",
      "85802/85802 [==============================] - 136s 2ms/sample - loss: 6.2652e-04 - acc: 0.9591 - val_loss: 0.0187 - val_acc: 0.0030\n",
      "Epoch 40/100\n",
      "85802/85802 [==============================] - 155s 2ms/sample - loss: 6.1445e-04 - acc: 0.9595 - val_loss: 0.0187 - val_acc: 0.0035\n",
      "Epoch 41/100\n",
      "85802/85802 [==============================] - 155s 2ms/sample - loss: 6.0424e-04 - acc: 0.9607 - val_loss: 0.0189 - val_acc: 0.0017\n",
      "Epoch 42/100\n",
      "85802/85802 [==============================] - 144s 2ms/sample - loss: 6.0132e-04 - acc: 0.9604 - val_loss: 0.0189 - val_acc: 0.0023\n",
      "Epoch 43/100\n",
      "85802/85802 [==============================] - 147s 2ms/sample - loss: 5.9582e-04 - acc: 0.9613 - val_loss: 0.0189 - val_acc: 0.0025\n",
      "Epoch 44/100\n",
      "85802/85802 [==============================] - 156s 2ms/sample - loss: 5.7600e-04 - acc: 0.9625 - val_loss: 0.0188 - val_acc: 8.9829e-04\n",
      "Epoch 45/100\n",
      "85802/85802 [==============================] - 141s 2ms/sample - loss: 5.7909e-04 - acc: 0.9622 - val_loss: 0.0189 - val_acc: 0.0018\n",
      "Epoch 46/100\n",
      "85802/85802 [==============================] - 155s 2ms/sample - loss: 5.6539e-04 - acc: 0.9628 - val_loss: 0.0190 - val_acc: 0.0020\n",
      "Epoch 47/100\n",
      "85802/85802 [==============================] - 168s 2ms/sample - loss: 5.5914e-04 - acc: 0.9637 - val_loss: 0.0189 - val_acc: 0.0018\n",
      "Epoch 48/100\n",
      "85802/85802 [==============================] - 145s 2ms/sample - loss: 5.5444e-04 - acc: 0.9639 - val_loss: 0.0191 - val_acc: 0.0025\n",
      "Epoch 49/100\n",
      "85802/85802 [==============================] - 143s 2ms/sample - loss: 5.5143e-04 - acc: 0.9640 - val_loss: 0.0190 - val_acc: 0.0027\n",
      "Epoch 50/100\n",
      "85802/85802 [==============================] - 170s 2ms/sample - loss: 5.4206e-04 - acc: 0.9650 - val_loss: 0.0190 - val_acc: 0.0025\n",
      "Epoch 51/100\n",
      "10800/85802 [==>...........................] - ETA: 2:08 - loss: 5.0171e-04 - acc: 0.9676"
     ]
    }
   ],
   "source": [
    "model = cnn.train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
